{"cells":[{"cell_type":"markdown","metadata":{"id":"2WRoeHk2BRLa"},"source":["# 수강생분의 이름, 학번을 반영해주세요."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1667897736987,"user":{"displayName":"안희진컴퓨터공학과","userId":"09104803564907682684"},"user_tz":-540},"id":"p6lZMos0BRLb","outputId":"b3a7bd08-2776-437c-e26a-6d09b6e3ff04"},"outputs":[{"output_type":"stream","name":"stdout","text":["20201944 안희진\n"]}],"source":["id = '20201944'\n","name = '안희진'\n","print(id, name)"]},{"cell_type":"markdown","metadata":{"id":"oFSdnGtSfPy2"},"source":["코랩 메뉴 -> 수정 -> 노트 설정 -> 하드웨어 가속기 GPU 권장(행렬 연산이 많기 때문)"]},{"cell_type":"markdown","metadata":{"id":"mmfPv3pvSyzW"},"source":["구글 드라이브 연동"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2516,"status":"ok","timestamp":1667897739881,"user":{"displayName":"안희진컴퓨터공학과","userId":"09104803564907682684"},"user_tz":-540},"id":"2Xgv13b9SylY","outputId":"d6cd2047-ba3e-480a-e57a-83102a222aeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"wjGCZX3rTDzf"},"source":["폴더 경로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPQ6ZqgNTEUp"},"outputs":[],"source":["workspace_path = '/gdrive/My Drive/3-2/인공지능/Al_week10'"]},{"cell_type":"markdown","metadata":{"id":"rb7H5Sj7unoc"},"source":["파이썬 패키지 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PqsCDfWurAU"},"outputs":[],"source":["import os\n","import sys\n","sys.path.append(os.path.join(workspace_path, 'PyTorch_CIFAR10-master'))  # PyTorch_CIFAR10 반영"]},{"cell_type":"markdown","metadata":{"id":"A24rzsRaNf4G"},"source":["필요 패키지 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f35aBUozTot0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"c-stOtMGg680"},"source":["결과 재현을 위한 설정 (GPU 연산방식에 따라 실험결과가 약간 다를 수 있음)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSMYLVv-g8a_"},"outputs":[],"source":["seed = 719\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"8H-POAtgNiXH"},"source":["합성곱 신경망(CNN) 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1667897739882,"user":{"displayName":"안희진컴퓨터공학과","userId":"09104803564907682684"},"user_tz":-540},"id":"73ayL6tKTtf1","outputId":"463027e8-aa62-4ba5-cfbe-f68b205d818d"},"outputs":[{"output_type":"stream","name":"stdout","text":["init model done\n"]}],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 3x32x32 -> 10x32x32\n","\n","            nn.BatchNorm2d(10),  # 배치 정규화\n","            nn.ReLU(inplace=True), #inplace=True는 기존의 데이터를 연산의 결괏값으로 대체하는 것을 의미\n","\n","            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 10x32x32 -> 20x32x32\n","            nn.BatchNorm2d(20),\n","            nn.ReLU(inplace=True),\n","\n","            nn.MaxPool2d(kernel_size=2),  # 20x32x32 -> 20x16x16 (특징 압축)\n","\n","            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 20x16x16 -> 40x16x16\n","            nn.BatchNorm2d(40),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=40, out_channels=80, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 40x8x8 -> 80x8x8\n","            nn.BatchNorm2d(80),\n","            \n","            nn.AdaptiveAvgPool2d(1)  # 80x8x8 -> 80x1x1 (채널 별 평균값 계산)\n","        )\n","        self.fc = nn.Linear(80, 10)  # 출력값의 차원은 판별할 클래스 수인 10으로 설정 (CIFAR-10 10종 판별 문제)\n","\n","    def forward(self, x):\n","        x = x.float()\n","        x = x.view(-1, 3, 32, 32)  # view 함수로 tensor 형태 변경: [batch크기, 3, 32, 32]\n","        x = self.main(x)  # CNN 모델 feed-forward\n","        x = x.view(-1, 80)  # view 함수로 형태 변경: [batch크기, 80]\n","        x = self.fc(x)  # 마지막 레이어에는 활성화 함수 사용하지 않음\n","        return x\n","\n","print(\"init model done\")"]},{"cell_type":"markdown","metadata":{"id":"8ubIJ-THNmsg"},"source":["모델 학습을 위한 하이퍼파라미터 셋팅"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1667897739882,"user":{"displayName":"안희진컴퓨터공학과","userId":"09104803564907682684"},"user_tz":-540},"id":"NIFF2C4VUsu2","outputId":"8931b534-8a9b-4444-9bb0-55c4417d3f00"},"outputs":[{"output_type":"stream","name":"stdout","text":["set vars and device done\n"]}],"source":["batch_size = 64  # 학습 배치 크기\n","test_batch_size = 1000  # 테스트 배치 크기 (학습 과정을 제외하므로 더 큰 배치 사용 가능)\n","max_epochs = 10  # 학습 데이터셋 총 훈련 횟수\n","lr = 0.001  # 학습률\n","momentum = 0.5  # SGD에 사용할 모멘텀 설정 (파라미터 업데이트 시 관성 효과 사용)\n","log_interval = 200  # interval 때마다 로그 남김\n","\n","use_cuda = torch.cuda.is_available()  # GPU cuda 사용 여부 확인\n","\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # GPU cuda 사용하거나 없다면 CPU 사용\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}  # num_workers: data loading할 프로세스 수, pin_memory: 고정된 메모리 영역 사용\n","\n","print(\"set vars and device done\")"]},{"cell_type":"markdown","metadata":{"id":"yobSwgppPEPB"},"source":["데이터 로더 정의 (학습용, 테스트용 따로 정의)"]},{"cell_type":"code","source":["mean = [0.4914, 0.4822, 0.4465]\n","std = [0.2471, 0.2435, 0.2616]"],"metadata":{"id":"zHWNPrIQXhx2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2153,"status":"ok","timestamp":1667897742030,"user":{"displayName":"안희진컴퓨터공학과","userId":"09104803564907682684"},"user_tz":-540},"id":"L_qvQSstUttY","outputId":"78efe439-8fa2-4510-dfe9-e4a49d561ce5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["train_transform = transforms.Compose([\n","                 transforms.RandomCrop(32),\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((mean[0], mean[1], mean[2]), (std[0], std[1], std[2])),])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","val_transform = transforms.Compose([\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((mean[0], mean[1], mean[2]), (std[0], std[1], std[2]))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","# CIFAR-10 link: https://www.cs.toronto.edu/~kriz/cifar.html\n","# 학습용 데이터 로더 (CIFAR-10 학습 데이터셋 사용)\n","train_loader = torch.utils.data.DataLoader(\n","  datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=True, download=True, \n","                   transform=train_transform), \n","    batch_size = batch_size, shuffle=True, drop_last=True, **kwargs)  # drop_last: 마지막 미니배치 크기가 batch_size 이하면 drop \n","\n","# 테스트용 데이터 로더 (CIFAR-10 테스트 데이터셋 사용)\n","test_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=False, download=True,\n","                         transform=val_transform), \n","    batch_size=test_batch_size, shuffle=False, **kwargs)"]},{"cell_type":"code","source":["# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # 최적화 알고리즘 정의 (SGD 사용)\n","# criterion = nn.CrossEntropyLoss()  # 손실 함수 정의 (CrossEntropy 사용)"],"metadata":{"id":"6DpQnAdIzk1O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"772mQzMoPf6E"},"source":["모델, 최적화 알고리즘, 손실 함수 정의"]},{"cell_type":"code","source":["# from cifar10_models.vgg import vgg11_bn\n","# model = vgg11_bn(pretrained=True).to(device)  # VGG11 with BatchNorm pretrained model 로드"],"metadata":{"id":"nVLEsgoF-Bqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7g8ejQCWaZl"},"outputs":[],"source":["# 전이학습 예제 코드\n","from cifar10_models.resnet import resnet18\n","model = resnet18(pretrained=True).to(device)  # VGG11 with BatchNorm pretrained model 로드\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # 최적화 알고리즘 정의 (SGD 사용)\n","criterion = nn.CrossEntropyLoss()  # 손실 함수 정의 (CrossEntropy 사용)"]},{"cell_type":"markdown","metadata":{"id":"oEkVPA1JXpmX"},"source":["AverageMeter 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMjKwVdbXs6f"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{"id":"UEWH5E_yPr5x"},"source":["학습, 테스트용 함수 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6DiSca1AVKJZ"},"outputs":[],"source":["def train(log_interval, model, device, train_loader, optimizer, epoch):\n","    model.train()  # 모델 학습 모드 설정\n","    summary_loss = AverageMeter()  # 학습 손실값 기록 초기화\n","    summary_acc = AverageMeter() # 학습 정확도 기록 초기화\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)  # 현재 미니 배치의 데이터, 정답 불러옴\n","        optimizer.zero_grad()  # gradient 0으로 초기화\n","        output = model(data)  # 모델에 입력값 feed-forward\n","        loss = criterion(output, target)  # 예측값(클래스 별 score)과 정답간의 손실값 계산\n","        loss.backward()  # 손실값 역전파 (각 계층에서 gradient 계산, pytorch는 autograd로 gradient 자동 계산)\n","        optimizer.step()  # 모델의 파라미터 업데이트 (gradient 이용하여 파라미터 업데이트)\n","        summary_loss.update(loss.detach().item())  # 손실값 기록\n","        pred = output.argmax(dim=1, keepdim=True)  # 예측값 중에서 최고 score를 달성한 클래스 선발\n","        correct = pred.eq(target.view_as(pred)).sum().item()  # 정답과 예측 클래스가 일치한 개수\n","        summary_acc.update(correct / data.size(0))  # 정확도 기록\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}, Accuracy: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), summary_loss.avg, summary_acc.avg))\n","            \n","    return summary_loss.avg, summary_acc.avg\n","\n","def test(log_interval, model, device, test_loader):\n","    model.eval()  # 모델 검증 모드 설정 (inference mode)\n","    summary_loss = AverageMeter()  # 테스트 손실값 기록 초기화\n","    summary_acc = AverageMeter() # 테스트 정확도 기록 초기화\n","    with torch.no_grad():  # 검증 모드이므로 gradient 계산안함\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)  # 현재 미니 배치의 데이터, 정답 불러옴\n","            output = model(data)  # 모델에 입력값 feed-forward\n","\n","            loss = criterion(output, target)  # 예측값(클래스 별 score)과 정답간의 손실값 계산\n","            \n","            summary_loss.update(loss.detach().item())  # 손실값 기록\n","            pred = output.argmax(dim=1, keepdim=True)  # 예측값 중에서 최고 score를 달성한 클래스 선발\n","            correct = pred.eq(target.view_as(pred)).sum().item()  # 정답과 예측 클래스가 일치한 개수\n","            summary_acc.update(correct / data.size(0))  # 정확도 기록\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.6f}\\n'.format\n","          (summary_loss.avg, summary_acc.avg))  # 정답을 맞춘 개수 / 테스트셋 샘플 수 -> Accuracy\n","\n","    return summary_loss.avg, summary_acc.avg"]},{"cell_type":"markdown","metadata":{"id":"g2T5yl2ETeKL"},"source":["학습, 테스트, 모델 저장 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"830vHfcPWqVE","executionInfo":{"status":"ok","timestamp":1667898041127,"user_tz":-540,"elapsed":298757,"user":{"displayName":"안희진컴퓨터공학과","userId":"09104803564907682684"}},"outputId":"6df8a6c7-d2a3-4a56-926f-558bf5cb4fbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/50000 (0%)]\tAverage loss: 0.041281, Accuracy: 1.000000\n","Train Epoch: 1 [12800/50000 (26%)]\tAverage loss: 0.089654, Accuracy: 0.977690\n","Train Epoch: 1 [25600/50000 (51%)]\tAverage loss: 0.094280, Accuracy: 0.975998\n","Train Epoch: 1 [38400/50000 (77%)]\tAverage loss: 0.097252, Accuracy: 0.975016\n","\n","Test set: Average loss: 0.3135, Accuracy: 0.911500\n","\n","# save model: cifar10_cnn_model_best_acc_1-epoch.pt\n","\n","Train Epoch: 2 [0/50000 (0%)]\tAverage loss: 0.044793, Accuracy: 1.000000\n","Train Epoch: 2 [12800/50000 (26%)]\tAverage loss: 0.070618, Accuracy: 0.983287\n","Train Epoch: 2 [25600/50000 (51%)]\tAverage loss: 0.073436, Accuracy: 0.982738\n","Train Epoch: 2 [38400/50000 (77%)]\tAverage loss: 0.074134, Accuracy: 0.982243\n","\n","Test set: Average loss: 0.3312, Accuracy: 0.909000\n","\n","Train Epoch: 3 [0/50000 (0%)]\tAverage loss: 0.145480, Accuracy: 0.984375\n","Train Epoch: 3 [12800/50000 (26%)]\tAverage loss: 0.054720, Accuracy: 0.988728\n","Train Epoch: 3 [25600/50000 (51%)]\tAverage loss: 0.054329, Accuracy: 0.988661\n","Train Epoch: 3 [38400/50000 (77%)]\tAverage loss: 0.056804, Accuracy: 0.987625\n","\n","Test set: Average loss: 0.3431, Accuracy: 0.904500\n","\n","Train Epoch: 4 [0/50000 (0%)]\tAverage loss: 0.087386, Accuracy: 0.984375\n","Train Epoch: 4 [12800/50000 (26%)]\tAverage loss: 0.041625, Accuracy: 0.991993\n","Train Epoch: 4 [25600/50000 (51%)]\tAverage loss: 0.041560, Accuracy: 0.992246\n","Train Epoch: 4 [38400/50000 (77%)]\tAverage loss: 0.042643, Accuracy: 0.991733\n","\n","Test set: Average loss: 0.3415, Accuracy: 0.910000\n","\n","Train Epoch: 5 [0/50000 (0%)]\tAverage loss: 0.030819, Accuracy: 1.000000\n","Train Epoch: 5 [12800/50000 (26%)]\tAverage loss: 0.036179, Accuracy: 0.993548\n","Train Epoch: 5 [25600/50000 (51%)]\tAverage loss: 0.037053, Accuracy: 0.993571\n","Train Epoch: 5 [38400/50000 (77%)]\tAverage loss: 0.038008, Accuracy: 0.992902\n","\n","Test set: Average loss: 0.3238, Accuracy: 0.914000\n","\n","# save model: cifar10_cnn_model_best_acc_5-epoch.pt\n","\n","Train Epoch: 6 [0/50000 (0%)]\tAverage loss: 0.008608, Accuracy: 1.000000\n","Train Epoch: 6 [12800/50000 (26%)]\tAverage loss: 0.032762, Accuracy: 0.993937\n","Train Epoch: 6 [25600/50000 (51%)]\tAverage loss: 0.034286, Accuracy: 0.993376\n","Train Epoch: 6 [38400/50000 (77%)]\tAverage loss: 0.034185, Accuracy: 0.993500\n","\n","Test set: Average loss: 0.3533, Accuracy: 0.908000\n","\n","Train Epoch: 7 [0/50000 (0%)]\tAverage loss: 0.033409, Accuracy: 1.000000\n","Train Epoch: 7 [12800/50000 (26%)]\tAverage loss: 0.033904, Accuracy: 0.993392\n","Train Epoch: 7 [25600/50000 (51%)]\tAverage loss: 0.032603, Accuracy: 0.993688\n","Train Epoch: 7 [38400/50000 (77%)]\tAverage loss: 0.032253, Accuracy: 0.993708\n","\n","Test set: Average loss: 0.3394, Accuracy: 0.915700\n","\n","# save model: cifar10_cnn_model_best_acc_7-epoch.pt\n","\n","Train Epoch: 8 [0/50000 (0%)]\tAverage loss: 0.026324, Accuracy: 1.000000\n","Train Epoch: 8 [12800/50000 (26%)]\tAverage loss: 0.024923, Accuracy: 0.995802\n","Train Epoch: 8 [25600/50000 (51%)]\tAverage loss: 0.026175, Accuracy: 0.995168\n","Train Epoch: 8 [38400/50000 (77%)]\tAverage loss: 0.028720, Accuracy: 0.994436\n","\n","Test set: Average loss: 0.3388, Accuracy: 0.914200\n","\n","Train Epoch: 9 [0/50000 (0%)]\tAverage loss: 0.048846, Accuracy: 0.984375\n","Train Epoch: 9 [12800/50000 (26%)]\tAverage loss: 0.029819, Accuracy: 0.993159\n","Train Epoch: 9 [25600/50000 (51%)]\tAverage loss: 0.029243, Accuracy: 0.993415\n","Train Epoch: 9 [38400/50000 (77%)]\tAverage loss: 0.028710, Accuracy: 0.993864\n","\n","Test set: Average loss: 0.3309, Accuracy: 0.916500\n","\n","# save model: cifar10_cnn_model_best_acc_9-epoch.pt\n","\n","Train Epoch: 10 [0/50000 (0%)]\tAverage loss: 0.019224, Accuracy: 1.000000\n","Train Epoch: 10 [12800/50000 (26%)]\tAverage loss: 0.020168, Accuracy: 0.996968\n","Train Epoch: 10 [25600/50000 (51%)]\tAverage loss: 0.021915, Accuracy: 0.996181\n","Train Epoch: 10 [38400/50000 (77%)]\tAverage loss: 0.021497, Accuracy: 0.996308\n","\n","Test set: Average loss: 0.3389, Accuracy: 0.915700\n","\n","\n","\n","# Best accuracy model(91.65%): cifar10_cnn_model_best_acc_9-epoch.pt\n","\n"]}],"source":["best_acc = 0\n","best_epoch = 0\n","for epoch in range(1, max_epochs+1):\n","    train_loss, train_acc = train(log_interval, model, device, train_loader, optimizer, epoch)\n","    test_loss, test_acc = test(log_interval, model, device, test_loader)\n","\n","    # 테스트에서 best accuracy 달성하면 모델 저장\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        best_epoch = epoch\n","        torch.save(model, os.path.join(workspace_path, f'cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt'))\n","        print(f'# save model: cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')\n","\n","print(f'\\n\\n# Best accuracy model({best_acc * 100:.2f}%): cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')"]},{"cell_type":"markdown","metadata":{"id":"nRP04ogeUJkm"},"source":["# 실습과제"]},{"cell_type":"markdown","metadata":{"id":"_pEKYSYIAz9F"},"source":["## baseline 모델 성능: 62.70%\n","- GPU 연산방식에 따라 실험결과가 약간 다를 수 있음\n","- 본인 코드의 baseline 성능을 기준으로 잡을 것"]},{"cell_type":"markdown","metadata":{"id":"9Jlw_NQJArdR"},"source":["## baseline보다 성능 높이기"]},{"cell_type":"markdown","metadata":{"id":"F6T4aldug3ny"},"source":["### 1) baseline + 데이터증대 + 하이퍼파라미터 수정하여 성능 높이기 (다른 augmentation 패키지도 사용 가능)\n","torchvision augmentation 링크: https://pytorch.org/vision/stable/transforms.html"]},{"cell_type":"markdown","metadata":{"id":"FXaFzvW8a_Nl"},"source":["개선 모델 성능: 68.37%"]},{"cell_type":"markdown","metadata":{"id":"KCB2Tg-XBQFX"},"source":["개선 아이디어 설명:\n","데이터증대를 위해서 transforms.CenterCrop(32) 사용\n","1. lr = 0.001,momentum = 0.5 -> Best accuracy model(50.91%)\n","2. lr = 0.01,momentum = 0.5  -> Best accuracy model(59.16%)\n","3. lr = 0.01,momentum = 0.9  -> Best accuracy model(68.37%)"]},{"cell_type":"markdown","metadata":{"id":"70OpvQ0ygpKX"},"source":["### 2) 데이터증대 + 전이학습으로 성능 높이기 (다른 pretrained model도 사용 가능)\n","pretrained model 링크: https://github.com/huyvnphan/PyTorch_CIFAR10"]},{"cell_type":"markdown","metadata":{"id":"0GvAdfwEhCP_"},"source":["개선 모델 성능: 88.37%"]},{"cell_type":"markdown","metadata":{"id":"PnD6Kax_hEEK"},"source":["개선 아이디어 설명: \n","1. vgg11_bn, transforms.CenterCrop(32) -> Best accuracy model(88.24%)\n","2. resnet18, transforms.CenterCrop(32) -> Best accuracy model(88.37%)"]},{"cell_type":"markdown","metadata":{"id":"YyFJdO0BhtCs"},"source":["### 3) 데이터증대 + 전이학습 + 추가 아이디어로 성능 높이기 (학습 과정 출력 포함)"]},{"cell_type":"markdown","metadata":{"id":"OX-rCd-Lh3Ij"},"source":["*개선* 모델 성능: 91.65%"]},{"cell_type":"markdown","metadata":{"id":"0zHwNIdLh4Q5"},"source":["개선 아이디어 설명: 데이터증대 + 전이학습 + 하이퍼파라미터 튜닝으로 성능 향상\n","1. lr = 0.01, momentum = 0.9  -> Best accuracy model(81.00%)\n","2. lr = 0.01, momentum = 0.5  -> Best accuracy model(88.57%)\n","3. lr = 0.02, momentum = 0.5 -> Best accuracy model(86.79%)\n","4. lr = 0.02, momentum = 0.9 -> Best accuracy model(79.16%)\n","5. lr = 0.001, momentum = 0.5 -> Best accuracy model(91.65%)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1d8rScQLO9Ndv8LEXZsB4RlG1tC1SQh2Z","timestamp":1617804842085}]},"gpuClass":"standard","hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}